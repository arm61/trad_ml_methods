{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' theorem\n",
    "\n",
    "The main idea behind all Bayesian modelling is that our prior knowledge about aspects of the model can, and should, inform our results. \n",
    "This can take a variety of forms, it could be our understanding of certain parameter in our model or, as introduced previously, it may be our certainty about the model itself. \n",
    "Bayes' theorem is generally written as follows, \n",
    "\n",
    "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)}, $$\n",
    "\n",
    "where, $P(A)$ and $P(B)$ are the independent probabilities of $A$ and $B$, and $P(A|B)$ is the probability of $A$ given $B$ is true and vice-versa for $P(B|A)$.\n",
    "For our model selection problems, we will write Bayes' theorem with a slightly different phrasing,\n",
    "\n",
    "$$ P(H_x|\\mathbf{D}) = \\frac{P(\\mathbf{D}|H_x)P(H_x)}{P(\\mathbf{D})}, $$\n",
    "\n",
    "where, $H_x$ is our model (hypothesis), $P(\\mathbf{D}|H_x)$ is the evidence for this model, $P(H_x)$ is the prior porbability for the model, $P(H_x|\\mathbf{D})$ is the posterior probability, and $P(\\mathbf{D})$ is the probability associated with the measured data. \n",
    "This final object is a normalisation factor, and can be found as the sum of the evidence for every possible model. \n",
    "However, it is typically not feasible to evaluate the evidence for **every** model, therefore we cannot truly quantify the posterior probability. \n",
    "\n",
    "## The Bayes' factor\n",
    "\n",
    "Despite this, we can still use this formulation for the comparison of different models for the same data. \n",
    "\n",
    "$$\\frac{P(H_x|\\mathbf{D})}{P(H_y|\\mathbf{D})} = \\frac{P(\\mathbf{D}|H_x)}{P(\\mathbf{D}|H_y)} \\times \\frac{P(H_x)}{P(H_y)},$$\n",
    "\n",
    "where the probabilities associated with the data only cancel out. \n",
    "The ratio between the two models is known as the Bayes factor, $B_{xy}$, and offers insight into the relative evidence for the models. \n",
    "\n",
    "The Bayes' factor is typically interpretated using the Table {numref}`bayes-table` from the work of Kass and Raftery {cite}`kass_bayes_1995`.\n",
    "\n",
    " ```{list-table} Interpretation of the Bayes factor.\n",
    ":header-rows: 1\n",
    ":name: bayes-table\n",
    "\n",
    "* - $2ln(B_{xy})$\n",
    "  - Evidence against $H_y$\n",
    "* - $[0, 2)$\n",
    "  - Not worth more than a bare mention\n",
    "* - $[2, 6)$ \n",
    "  - Positive\n",
    "* - $[6, 10)$\n",
    "  - Strong\n",
    "* - $[10, \\infty)$\n",
    "  - Very strong\n",
    "```\n",
    "\n",
    "## Nested sampling\n",
    "\n",
    "We have seen how we can compare our different models, but nothing has been "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
