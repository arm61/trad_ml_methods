{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' theorem\n",
    "\n",
    "The main idea behind all Bayesian modelling is that our prior knowledge about aspects of the model can, and should, inform our results. \n",
    "This can take a variety of forms, it could be our understanding of certain parameter in our model or, as introduced previously, it may be our certainty about the model itself. \n",
    "Bayes' theorem is generally written as follows, \n",
    "\n",
    "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)}, $$\n",
    "\n",
    "where, $P(A)$ and $P(B)$ are the independent probabilities of $A$ and $B$, and $P(A|B)$ is the probability of $A$ given $B$ is true and vice-versa for $P(B|A)$.\n",
    "For our model selection problems, we will write Bayes' theorem with a slightly different phrasing,\n",
    "\n",
    "$$ P(H_x|\\mathbf{D}) = \\frac{P(\\mathbf{D}|H_x)P(H_x)}{P(\\mathbf{D})}, $$\n",
    "\n",
    "where, $H_x$ is our model (hypothesis), $P(\\mathbf{D}|H_x)$ is the evidence for this model, $P(H_x)$ is the prior porbability for the model, $P(H_x|\\mathbf{D})$ is the posterior probability, and $P(\\mathbf{D})$ is the probability associated with the measured data. \n",
    "This final object is a normalisation factor, and can be found as the sum of the evidence for every possible model. \n",
    "However, it is typically not feasible to evaluate the evidence for **every** model, therefore we cannot truly quantify the posterior probability. \n",
    "\n",
    "## The Bayes' factor\n",
    "\n",
    "Despite this, we can still use this formulation for the comparison of different models for the same data. \n",
    "\n",
    "$$\\frac{P(H_x|\\mathbf{D})}{P(H_y|\\mathbf{D})} = \\frac{P(\\mathbf{D}|H_x)}{P(\\mathbf{D}|H_y)} \\times \\frac{P(H_x)}{P(H_y)},$$\n",
    "\n",
    "where the probabilities associated with the data only cancel out. \n",
    "The ratio between the two models is known as the Bayes factor, $B_{xy}$, and offers insight into the relative evidence for the models. \n",
    "\n",
    "The Bayes' factor is typically interpretated using the table below from the work of Kass and Raftery {cite}`kass_bayes_1995`.\n",
    "Typically, for Bayesian model selection, we are comparing models with different numbers of parameters. \n",
    "In this interpretation of the Bayes factor, the model $H_y$ has fewer parameters than $H_x$ and therefore for the latter model to be considered \"better\" is it necessary to have a substantially better evidence. \n",
    "We can think of this as a quantification of Occam's razor. \n",
    "\n",
    "| $2\\ln(B_{xy})$ | Evidence against $H_y$ |\n",
    "|---|---|\n",
    "| $[0, 2)$ | Not worth a bare mention |\n",
    "| $[2, 6)$ | Positive |\n",
    "| $[6, 10)$ | Strong | \n",
    "| $[10, \\infty)$ | Very strong |\n",
    "\n",
    "\n",
    "## Evidence\n",
    "\n",
    "We have seen how we can compare our different models, but nothing has been said thus far about how the evidence is determined. \n",
    "The evidence is the integral under the product of the likelihood, $\\mathcal{L}(\\mathbf{X}|H)$, and the parameter specific prior, $P(\\mathbf{X}|H)$, \n",
    "\n",
    "$$ P(\\mathbf{D}|H) = \\iint_{\\mathbf{R}} \\mathcal{L}(\\mathbf{X}|H)P(\\mathbf{X}|H)\\; \\text{d}^M\\mathbf{X}, $$\n",
    "\n",
    "where, $\\mathbf{X}$ is a vector of length $M$ of the parameters that are varying in the model, $\\mathbf{R}$ is a $2\\times M$ matrix describing the range over which the integral should be evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
